@article{Denoyelle_2020,
doi = {10.1088/1361-6420/ab2a29},
url = {https://dx.doi.org/10.1088/1361-6420/ab2a29},
year = {2019},
month = {dec},
publisher = {IOP Publishing},
volume = {36},
number = {1},
pages = {014001},
author = {Quentin Denoyelle and Vincent Duval and Gabriel Peyré and Emmanuel Soubies},
title = {The sliding Frank–Wolfe algorithm and its application to super-resolution microscopy},
journal = {Inverse Problems},
abstract = {This paper showcases the theoretical and numerical performance of the Sliding Frank–Wolfe, which is a novel optimization algorithm to solve the BLASSO sparse spikes super-resolution problem. The BLASSO is a continuous (i.e. off-the-grid or grid-less) counterpart to the well-known  sparse regularisation method (also known as LASSO or basis pursuit). Our algorithm is a variation on the classical Frank–Wolfe (also known as conditional gradient) which follows a recent trend of interleaving convex optimization updates (corresponding to adding new spikes) with non-convex optimization steps (corresponding to moving the spikes). Our main theoretical result is that this algorithm terminates in a finite number of steps under a mild non-degeneracy hypothesis. We then target applications of this method to several instances of single molecule fluorescence imaging modalities, among which certain approaches rely heavily on the inversion of a Laplace transform. Our second theoretical contribution is the proof of the exact support recovery property of the BLASSO to invert the 1D Laplace transform in the case of positive spikes. On the numerical side, we conclude this paper with an extensive study of the practical performance of the Sliding Frank–Wolfe on different instantiations of single molecule fluorescence imaging, including convolutive and non-convolutive (Laplace-like) operators. This shows the versatility and superiority of this method with respect to alternative sparse recovery technics.}
}

@Article{Candes2012,
  author      = {Emmanuel J. Cand{\`{e}}s and Carlos Fernandez-Granda},
  journal     = {Communications on Pure and Applied Mathematics},
  title       = {Towards a Mathematical Theory of Super-resolution},
  year        = {2013},
  month       = {apr},
  number      = {6},
  pages       = {906--956},
  volume      = {67},
  abstract    = {This paper develops a mathematical theory of super-resolution. Broadly speaking, super-resolution is the problem of recovering the fine details of an object---the high end of its spectrum---from coarse scale information only---from samples at the low end of the spectrum. Suppose we have many point sources at unknown locations in $[0,1]$ and with unknown complex-valued amplitudes. We only observe Fourier samples of this object up until a frequency cut-off $f_c$. We show that one can super-resolve these point sources with infinite precision---i.e. recover the exact locations and amplitudes---by solving a simple convex optimization problem, which can essentially be reformulated as a semidefinite program. This holds provided that the distance between sources is at least $2/f_c$. This result extends to higher dimensions and other models. In one dimension for instance, it is possible to recover a piecewise smooth function by resolving the discontinuity points with infinite precision as well. We also show that the theory and methods are robust to noise. In particular, in the discrete setting we develop some theoretical results explaining how the accuracy of the super-resolved signal is expected to degrade when both the noise level and the {\em super-resolution factor} vary.},
  date        = {2012-03-27},
  doi         = {10.1002/cpa.21455},
  eprint      = {1203.5871},
  eprintclass = {cs.IT},
  eprinttype  = {arXiv},
  file        = {:Candes2012 - Towards a Mathematical Theory of Super Resolution.pdf:PDF},
  keywords    = {cs.IT, math.IT, math.NA},
  publisher   = {Wiley},
}

@Article{Castro2015,
  author      = {Yohann De Castro and F. Gamboa and Didier Henrion and J.-B. Lasserre},
  journal     = {{IEEE} Transactions on Information Theory},
  title       = {Exact solutions to Super Resolution on semi-algebraic domains in higher dimensions},
  year        = {2017},
  month       = {jan},
  number      = {1},
  pages       = {621--630},
  volume      = {63},
  abstract    = {We investigate the multi-dimensional Super Resolution problem on closed semi-algebraic domains for various sampling schemes such as Fourier or moments. We present a new semidefinite programming (SDP) formulation of the 1 -minimization in the space of Radon measures in the multi-dimensional frame on semi-algebraic sets. While standard approaches have focused on SDP relaxations of the dual program (a popular approach is based on Gram matrix representations), this paper introduces an exact formulation of the primal 1 -minimization exact recovery problem of Super Resolution that unleashes standard techniques (such as moment-sum-of-squares hier-archies) to overcome intrinsic limitations of previous works in the literature. Notably, we show that one can exactly solve the Super Resolution problem in dimension greater than 2 and for a large family of domains described by semi-algebraic sets.},
  date        = {2015-02-09},
  doi         = {10.1109/tit.2016.2619368},
  eprint      = {1502.02436},
  eprintclass = {cs.IT},
  eprinttype  = {arXiv},
  file        = {:Castro2015 - Exact Solutions to Super Resolution on Semi Algebraic Domains in Higher Dimensions.pdf:PDF},
  keywords    = {cs.IT, math.IT, math.OC, stat.CO},
  publisher   = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Article{Bredies2012,
  author    = {Kristian Bredies and Hanna Katriina Pikkarainen},
  journal   = {{ESAIM}: Control, Optimisation and Calculus of Variations},
  title     = {Inverse problems in spaces of measures},
  year      = {2012},
  month     = {mar},
  number    = {1},
  pages     = {190--218},
  volume    = {19},
  abstract  = {The ill-posed problem of solving linear equations in the space of vector-valued finite Radon measures with Hilbert space data is considered. Approximate solutions are obtained by minimizing the Tikhonov functional with a total variation penalty. The well-posedness of this regularization method and further regularization properties are mentioned. Furthermore, a flexible numerical minimization algorithm is proposed which converges subsequentially in the weak* sense and with rate O(n-1) in terms of the functional values. Finally, numerical results for sparse deconvolution demonstrate the applicability for a finite-dimensional discrete data space and infinite-dimensional solution space.},
  doi       = {10.1051/cocv/2011205},
  file      = {:Bredies2012 - Inverse Problems in Spaces of Measures.pdf:PDF},
  publisher = {{EDP} Sciences},
}

@Article{Duval2014,
  author      = {Vincent Duval and Gabriel Peyré},
  journal     = {Foundations of Computational Mathematics},
  title       = {Exact Support Recovery for Sparse Spikes Deconvolution},
  year        = {2014},
  month       = {oct},
  number      = {5},
  pages       = {1315--1355},
  volume      = {15},
  abstract    = {This paper studies sparse spikes deconvolution over the space of measures. We focus our attention to the recovery properties of the support of the measure, i.e. the location of the Dirac masses. For non-degenerate sums of Diracs, we show that, when the signal-to-noise ratio is large enough, total variation regularization (which is the natural extension of the L1 norm of vectors to the setting of measures) recovers the exact same number of Diracs. We also show that both the locations and the heights of these Diracs converge toward those of the input measure when the noise drops to zero. The exact speed of convergence is governed by a specific dual certificate, which can be computed by solving a linear system. We draw connections between the support of the recovered measure on a continuous domain and on a discretized grid. We show that when the signal-to-noise level is large enough, the solution of the discretized problem is supported on pairs of Diracs which are neighbors of the Diracs of the input measure. This gives a precise description of the convergence of the solution of the discretized problem toward the solution of the continuous grid-free problem, as the grid size tends to zero.},
  date        = {2013-06-28},
  doi         = {10.1007/s10208-014-9228-6},
  eprint      = {1306.6909},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:Duval2014 - Exact Support Recovery for Sparse Spikes Deconvolution.pdf:PDF},
  keywords    = {math.OC, cs.IT, math.IT, math.NA},
  publisher   = {Springer Science and Business Media {LLC}},
}

@Book{Federer1996,
  author    = {Federer, Herbert},
  publisher = {Springer},
  title     = {Geometric measure theory},
  year      = {1996},
  address   = {Berlin},
  isbn      = {9783642620102},
}

@Article{jimaging7120266,
AUTHOR = {Laville, Bastien and Blanc-Féraud, Laure and Aubert, Gilles},
TITLE = {Off-The-Grid Variational Sparse Spike Recovery: Methods and Algorithms},
JOURNAL = {Journal of Imaging},
VOLUME = {7},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {266},
URL = {https://www.mdpi.com/2313-433X/7/12/266},
PubMedID = {34940733},
ISSN = {2313-433X},
ABSTRACT = {Gridless sparse spike reconstruction is a rather new research field with significant results for the super-resolution problem, where we want to retrieve fine-scale details from a noisy and filtered acquisition. To tackle this problem, we are interested in optimisation under some prior, typically the sparsity i.e., the source is composed of spikes. Following the seminal work on the generalised LASSO for measures called the Beurling-Lasso (BLASSO), we will give a review on the chief theoretical and numerical breakthrough of the off-the-grid inverse problem, as we illustrate its usefulness to the super-resolution problem in Single Molecule Localisation Microscopy (SMLM) through new reconstruction metrics and tests on synthetic and real SMLM data we performed for this review.},
DOI = {10.3390/jimaging7120266}
}

@Article{Tibshirani1996,
  author    = {Robert Tibshirani},
  journal   = {Journal of the Royal Statistical Society: Series B (Methodological)},
  title     = {Regression Shrinkage and Selection Via the Lasso},
  year      = {1996},
  month     = {jan},
  number    = {1},
  pages     = {267--288},
  volume    = {58},
  doi       = {10.1111/j.2517-6161.1996.tb02080.x},
  publisher = {Wiley},
}

@Article{Castro2012,
  author      = {Yohann de Castro and Fabrice Gamboa},
  journal     = {Journal of Mathematical Analysis and Applications},
  title       = {Exact reconstruction using Beurling minimal extrapolation},
  year        = {2012},
  month       = {nov},
  number      = {1},
  pages       = {336--354},
  volume      = {395},
  abstract    = {We show that measures with finite support on the real line are the unique solution to an algorithm, named generalized minimal extrapolation, involving only a finite number of generalized moments (which encompass the standard moments, the Laplace transform, the Stieltjes transformation, etc). Generalized minimal extrapolation shares related geometric properties with basis pursuit of Chen, Donoho and Saunders [CDS98]. Indeed we also extend some standard results of compressed sensing (the dual polynomial, the nullspace property) to the signed measure framework. We express exact reconstruction in terms of a simple interpolation problem. We prove that every nonnegative measure, supported by a set containing s points,can be exactly recovered from only 2s + 1 generalized moments. This result leads to a new construction of deterministic sensing matrices for compressed sensing.},
  date        = {2011-03-25},
  doi         = {10.1016/j.jmaa.2012.05.011},
  eprint      = {1103.4951},
  eprintclass = {math.ST},
  eprinttype  = {arXiv},
  file        = {:Castro2012 - Exact Reconstruction Using Beurling Minimal Extrapolation.pdf:PDF;:http\://arxiv.org/pdf/1103.4951v2:PDF},
  keywords    = {math.ST, cs.IT, math.IT, math.OC, math.PR, stat.TH},
  publisher   = {Elsevier {BV}},
}

@article{doi:10.1137/080716542,
author = {Beck, Amir and Teboulle, Marc},
title = {A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems},
journal = {SIAM Journal on Imaging Sciences},
volume = {2},
number = {1},
pages = {183-202},
year = {2009},
doi = {10.1137/080716542},
URL = { 
        https://doi.org/10.1137/080716542
},
eprint = { 
        https://doi.org/10.1137/080716542
}
,
    abstract = { Abstract. We consider the class of iterative shrinkage-thresholding algorithms (ISTA) for solving linear inverse problems arising in signal/image processing. This class of methods, which can be viewed as an extension of the classical gradient algorithm, is attractive due to its simplicity and thus is adequate for solving large-scale problems even with dense matrix data. However, such methods are also known to converge quite slowly. In this paper we present a new fast iterative shrinkage-thresholding algorithm (FISTA) which preserves the computational simplicity of ISTA but with a global rate of convergence which is proven to be significantly better, both theoretically and practically. Initial promising numerical results for wavelet-based image deblurring demonstrate the capabilities of FISTA which is shown to be faster than ISTA by several orders of magnitude. }
}

@article{Wu_2008,
   title={Coordinate descent algorithms for lasso penalized regression},
   volume={2},
   ISSN={1932-6157},
   url={http://dx.doi.org/10.1214/07-AOAS147},
   DOI={10.1214/07-aoas147},
   number={1},
   journal={The Annals of Applied Statistics},
   publisher={Institute of Mathematical Statistics},
   author={Wu, Tong Tong and Lange, Kenneth},
   year={2008},
   month=mar }

@article{Catala_2017,
   title={A low-rank approach to off-the-grid sparse deconvolution},
   volume={904},
   ISSN={1742-6596},
   url={http://dx.doi.org/10.1088/1742-6596/904/1/012015},
   DOI={10.1088/1742-6596/904/1/012015},
   journal={Journal of Physics: Conference Series},
   publisher={IOP Publishing},
   author={Catala, Paul and Duval, Vincent and Peyré, Gabriel},
   year={2017},
   month=oct, pages={012015} }

@Article{Frank1956,
  author    = {Marguerite Frank and Philip Wolfe},
  journal   = {Naval Research Logistics Quarterly},
  title     = {An algorithm for quadratic programming},
  year      = {1956},
  month     = {mar},
  number    = {1-2},
  pages     = {95--110},
  volume    = {3},
  comment   = {Frank-Wolfe algorithm},
  doi       = {10.1002/nav.3800030109},
  publisher = {Wiley},
}

@InProceedings{Boyd2015,
  author      = {Nicholas Boyd and Geoffrey Schiebinger and Benjamin Recht},
  booktitle   = {2015 {IEEE} 6th International Workshop on Computational Advances in Multi-Sensor Adaptive Processing ({CAMSAP})},
  title       = {The alternating descent conditional gradient method for sparse inverse problems},
  year        = {2015},
  month       = {dec},
  publisher   = {{IEEE}},
  abstract    = {We propose a variant of the classical conditional gradient method for sparse inverse problems with differentiable measurement models. Such models arise in many practical problems including superresolution, time-series modeling, and matrix completion. Our algorithm combines nonconvex and convex optimization techniques: we propose global conditional gradient steps alternating with nonconvex local search exploiting the differentiable measurement model. This hybridization gives the theoretical global optimality guarantees and stopping conditions of convex optimization along with the performance and modeling flexibility associated with nonconvex optimization. Our experiments demonstrate that our technique achieves state-of-the-art results in several applications.},
  comment     = {Conditional gradient = Frnak-Wolfe actually},
  date        = {2015-07-06},
  doi         = {10.1109/camsap.2015.7383735},
  eprint      = {1507.01562},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1507.01562v1:PDF},
  keywords    = {math.OC},
}

@Article{Levitin1966,
  author    = {E.S. Levitin and B.T. Polyak},
  journal   = {{USSR} Computational Mathematics and Mathematical Physics},
  title     = {Constrained minimization methods},
  year      = {1966},
  month     = {jan},
  number    = {5},
  pages     = {1--50},
  volume    = {6},
  comment   = {L-BFGS-B but soviet},
  doi       = {10.1016/0041-5553(66)90114-5},
  publisher = {Elsevier {BV}},
}

@Article{Harchaoui2013,
  author      = {Zaid Harchaoui and Anatoli Juditsky and Arkadi Nemirovski},
  journal     = {Mathematical Programming},
  title       = {Conditional gradient algorithms for norm-regularized smooth convex optimization},
  year        = {2014},
  month       = {apr},
  number      = {1-2},
  pages       = {75--112},
  volume      = {152},
  abstract    = {Motivated by some applications in signal processing and machine learning, we consider two convex optimization problems where, given a cone $K$, a norm $\|\cdot\|$ and a smooth convex function $f$, we want either 1) to minimize the norm over the intersection of the cone and a level set of $f$, or 2) to minimize over the cone the sum of $f$ and a multiple of the norm. We focus on the case where (a) the dimension of the problem is too large to allow for interior point algorithms, (b) $\|\cdot\|$ is "too complicated" to allow for computationally cheap Bregman projections required in the first-order proximal gradient algorithms. On the other hand, we assume that {it is relatively easy to minimize linear forms over the intersection of $K$ and the unit $\|\cdot\|$-ball}. Motivating examples are given by the nuclear norm with $K$ being the entire space of matrices, or the positive semidefinite cone in the space of symmetric matrices, and the Total Variation norm on the space of 2D images. We discuss versions of the Conditional Gradient algorithm capable to handle our problems of interest, provide the related theoretical efficiency estimates and outline some applications.},
  date        = {2013-02-10},
  doi         = {10.1007/s10107-014-0778-9},
  eprint      = {1302.2325},
  eprintclass = {math.OC},
  eprinttype  = {arXiv},
  file        = {:Harchaoui2013 - Conditional Gradient Algorithms for Norm Regularized Smooth Convex Optimization.pdf:PDF},
  keywords    = {math.OC, stat.CO, stat.ML},
  publisher   = {Springer Science and Business Media {LLC}},
}

@article{Jarret_2022,
   title={A Fast and Scalable Polyatomic Frank-Wolfe Algorithm for the LASSO},
   volume={29},
   ISSN={1558-2361},
   url={http://dx.doi.org/10.1109/LSP.2022.3149377},
   DOI={10.1109/lsp.2022.3149377},
   journal={IEEE Signal Processing Letters},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Jarret, Adrian and Fageot, Julien and Simeoni, Matthieu},
   year={2022},
   pages={637–641} }

@INPROCEEDINGS{488968,
  author={Kennedy, J. and Eberhart, R.},
  booktitle={Proceedings of ICNN'95 - International Conference on Neural Networks}, 
  title={Particle swarm optimization}, 
  year={1995},
  volume={4},
  number={},
  pages={1942-1948 vol.4},
  keywords={Particle swarm optimization;Birds;Educational institutions;Marine animals;Testing;Humans;Genetic algorithms;Optimization methods;Artificial neural networks;Performance evaluation},
  doi={10.1109/ICNN.1995.488968}}

@ARTICLE{9258416,
  author={Koulouri, Alexandra and Heins, Pia and Burger, Martin},
  journal={IEEE Transactions on Signal Processing}, 
  title={Adaptive Superresolution in Deconvolution of Sparse Peaks}, 
  year={2021},
  volume={69},
  number={},
  pages={165-178},
  keywords={Kernel;Deconvolution;Minimization;Convolution;TV;Standards;Extraterrestrial measurements;Deconvolution;superresolution;sparsity; $\ell _1$ -norm;LASSO;first order optimality condition;grid;discretization;node;element;smooth and symmetric kernel},
  doi={10.1109/TSP.2020.3037373}}

@misc{denoyelle2021optimaltransportbasedmetricsmlm,
      title={Optimal-transport-based metric for SMLM}, 
      author={Quentin Denoyelle and Thanh-an Pham and Pol del Aguila Pla and Daniel Sage and Michael Unser},
      year={2021},
      eprint={2010.13423},
      archivePrefix={arXiv},
      primaryClass={eess.IV},
      url={https://arxiv.org/abs/2010.13423}, 
}

@misc{ramdas2015wassersteinsampletestingrelated,
      title={On Wasserstein Two Sample Testing and Related Families of Nonparametric Tests}, 
      author={Aaditya Ramdas and Nicolas Garcia and Marco Cuturi},
      year={2015},
      eprint={1509.02237},
      archivePrefix={arXiv},
      primaryClass={math.ST},
      url={https://arxiv.org/abs/1509.02237}, 
}

@Article{Sage2015,
  author    = {Daniel Sage and Hagai Kirshner and Thomas Pengo and Nico Stuurman and Junhong Min and Suliana Manley and Michael Unser},
  journal   = {Nature Methods},
  title     = {Quantitative evaluation of software packages for single-molecule localization microscopy},
  year      = {2015},
  month     = {jun},
  number    = {8},
  pages     = {717--724},
  volume    = {12},
  doi       = {10.1038/nmeth.3442},
  publisher = {Springer Science and Business Media {LLC}},
}